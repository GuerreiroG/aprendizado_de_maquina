{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Alunos: Daniel de Paula, Gustavo Guerreiro e Mayara Cardoso Simões\n",
    "\n",
    "# Trabalho Final de Aprendizado de Máquina sobre Visão Computacional: Classificação de Imagens de Cães e Gatos\n",
    "\n",
    "O dataset utilizado é de propriedade da Microsoft e está disponível em: https://www.kaggle.com/datasets/shaunthesheep/microsoft-catsvsdogs-dataset"
   ],
   "id": "9f0d390d8467b71a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Separação dos Dados em Treino, Teste e Validação\n",
    "\n",
    "A primeira etapa da implementação é a de separação dos dados. Inicialmente o diretório se encontra no formato:\n",
    "```\n",
    "PetImages/\n",
    "├── Cat\n",
    "└── Dog\n",
    "```\n",
    "\n",
    "Como uma Rede Neural necessita de uma separação entre treino, teste e possivelmente validação, o dataset será reorganizado para seguir a seguinte estrutura mais comum nesse tipo de implementação:\n",
    "```\n",
    "dataset/\n",
    "├── train/\n",
    "│   ├── Cat/\n",
    "│   └── Dog/\n",
    "├── val/\n",
    "│   ├── Cat/\n",
    "│   └── Dog/\n",
    "└── test/\n",
    "    ├── Cat/\n",
    "    └── Dog/\n",
    "```\n",
    "Para usar essa estrutura se utilizou a classe GeneratorBasedBuilder do TensorFlow para fazer a divisão mais eficiente e monstar a estrutura em treino, validação e teste."
   ],
   "id": "a939e462a4c52827"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importação das bibliotecas",
   "id": "d48ca4ecdea04ab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:18:28.577101Z",
     "start_time": "2025-11-16T03:18:28.572100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "from glob import glob\n",
    "from random import Random\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow_datasets.core import GeneratorBasedBuilder, DatasetInfo, Version\n",
    "\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ],
   "id": "3ae5740f62974910",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definição da Classe do Dataset\n",
    "\n",
    "Para organizar o dataset de uma forma mais eficiente foi criada a classe CatsDogs.\n",
    "Inicialmente se tem uma função auxiliar chamada listar_imagens_validas, ela é usada para checar se a imagem sendo tratada é de fato um jpg válido ou foi corrompido.\n",
    "\n",
    "Já a classe CatsDogs em si possui três métodos:\n",
    "* _info: contém as informações contidas no dataset, no caso uma imagem de 3 dimensões (altura, largura e cor RGB) e o rótulo podendo ser \"Cat\" ou Dog.\n",
    "* _split_generators: método principal que busca nas pastas as imagens dos gatos e cães, separa cada grupo em treino, validação e teste e então junta as imagens de cada animal.\n",
    "* _generate_examples: usado para gerar os dados retornados em si, pegando cada imagem e atribuindo um id para ela."
   ],
   "id": "b3e0fea64942285b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-16T03:18:28.605392Z",
     "start_time": "2025-11-16T03:18:28.598272Z"
    }
   },
   "source": [
    "def listar_imagens_validas(pasta, label):\n",
    "    caminhos = glob(f\"{pasta}/*\")\n",
    "    validos = []\n",
    "    for caminho in caminhos:\n",
    "        if imghdr.what(caminho) == \"jpeg\":\n",
    "            validos.append((caminho, label))\n",
    "    return validos\n",
    "\n",
    "\n",
    "class CatsDogs(GeneratorBasedBuilder):\n",
    "    VERSION = Version(\"1.0.0\")\n",
    "    SEED = 42\n",
    "    PASTA_PADRAO = \"PetImages\"\n",
    "\n",
    "    def _info(self):\n",
    "        return DatasetInfo(\n",
    "            builder=self,\n",
    "            features=tfds.features.FeaturesDict({\n",
    "                \"image\": tfds.features.Image(shape=(None, None, 3)),\n",
    "                \"label\": tfds.features.ClassLabel(names=[\"Cat\", \"Dog\"]),\n",
    "            })\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        raiz = self.PASTA_PADRAO\n",
    "\n",
    "        gatos = listar_imagens_validas(f\"{raiz}/Cat\", 0)\n",
    "        caes = listar_imagens_validas(f\"{raiz}/Dog\", 1)\n",
    "\n",
    "        gatos_treino, gatos_resto = train_test_split(gatos, test_size=0.3, random_state=self.SEED)\n",
    "        gatos_val, gatos_test = train_test_split(gatos_resto, test_size=0.5, random_state=self.SEED)\n",
    "\n",
    "        caes_treino, caes_resto = train_test_split(caes, test_size=0.3, random_state=self.SEED)\n",
    "        caes_val, caes_test = train_test_split(caes_resto, test_size=0.5, random_state=self.SEED)\n",
    "\n",
    "        rng = Random(self.SEED)\n",
    "        treino = gatos_treino + caes_treino\n",
    "        rng.shuffle(treino)\n",
    "\n",
    "        val = gatos_val + caes_val\n",
    "        rng.shuffle(val)\n",
    "\n",
    "        teste = gatos_test + caes_test\n",
    "        rng.shuffle(teste)\n",
    "\n",
    "        return {\n",
    "            \"train\": self._generate_examples(treino),\n",
    "            \"val\": self._generate_examples(val),\n",
    "            \"test\": self._generate_examples(teste)\n",
    "        }\n",
    "\n",
    "    def _generate_examples(self, arquivos):\n",
    "        for caminho, rotulo in arquivos:\n",
    "            if not path.isfile(caminho):\n",
    "                continue\n",
    "            yield caminho, {\"image\": caminho, \"label\": rotulo}\n"
   ],
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Instanciamento dos Datasets\n",
    "A classe CatsDogs é instanciada e os datasets são construídos e carredos em variáveis."
   ],
   "id": "57ca7b7713416d1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:19:14.286490Z",
     "start_time": "2025-11-16T03:18:28.619374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder = CatsDogs()\n",
    "builder.download_and_prepare()\n",
    "\n",
    "ds_train = builder.as_dataset(split=\"train\")\n",
    "ds_val = builder.as_dataset(split=\"val\")\n",
    "ds_test = builder.as_dataset(split=\"test\")"
   ],
   "id": "7951817f7f314da0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\guto_\\tensorflow_datasets\\cats_dogs\\1.0.0...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001B[A\n",
      "Generating train examples...: 2337 examples [00:01, 2335.83 examples/s]\u001B[A\n",
      "Generating train examples...: 5175 examples [00:02, 2630.61 examples/s]\u001B[A\n",
      "Generating train examples...: 8043 examples [00:03, 2738.71 examples/s]\u001B[A\n",
      "Generating train examples...: 11017 examples [00:04, 2831.22 examples/s]\u001B[A\n",
      "Generating train examples...: 13944 examples [00:05, 2865.41 examples/s]\u001B[A\n",
      "Generating train examples...: 16944 examples [00:06, 2911.04 examples/s]\u001B[A\n",
      "                                                                        \u001B[A\n",
      "Shuffling C:\\Users\\guto_\\tensorflow_datasets\\cats_dogs\\incomplete.28UBWP_1.0.0\\cats_dogs-train.tfrecord*...:   0%|          | 0/17320 [00:00<?, ? examples/s]\u001B[A\n",
      "Generating splits...:  33%|███▎      | 1/3 [00:06<00:13,  6.93s/ splits]                                                                                     \u001B[A\n",
      "Generating val examples...: 0 examples [00:00, ? examples/s]\u001B[A\n",
      "Generating val examples...: 2530 examples [00:01, 2527.76 examples/s]\u001B[A\n",
      "                                                                     \u001B[A\n",
      "Shuffling C:\\Users\\guto_\\tensorflow_datasets\\cats_dogs\\incomplete.28UBWP_1.0.0\\cats_dogs-val.tfrecord*...:   0%|          | 0/3712 [00:00<?, ? examples/s]\u001B[A\n",
      "Generating splits...:  67%|██████▋   | 2/3 [00:08<00:03,  3.83s/ splits]                                                                                  \u001B[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001B[A\n",
      "Generating test examples...: 2972 examples [00:01, 2971.36 examples/s]\u001B[A\n",
      "                                                                      \u001B[A\n",
      "Shuffling C:\\Users\\guto_\\tensorflow_datasets\\cats_dogs\\incomplete.28UBWP_1.0.0\\cats_dogs-test.tfrecord*...:   0%|          | 0/3712 [00:00<?, ? examples/s]\u001B[A\n",
      "                                                                                                                                                           \u001B[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset cats_dogs downloaded and prepared to C:\\Users\\guto_\\tensorflow_datasets\\cats_dogs\\1.0.0. Subsequent calls will reuse this data.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pré-Processamento\n",
    "As imagens são pré processados, tendo inicialmente o seu tamanho ajustado e então os seus valores normalizados do formato RGB (0-255, 0-255, 0-255) para (0.0-1.0, 0.0-1.0, 0.0-1.0)."
   ],
   "id": "4964b6295430bd7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:18:28.614370Z",
     "start_time": "2025-11-16T03:18:28.610396Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 164,
   "source": [
    "TAMANHO = 128\n",
    "\n",
    "def preprocessamento(dicionario):\n",
    "    image = dicionario[\"image\"]\n",
    "    label = dicionario[\"label\"]\n",
    "    image = tf.image.resize(image, (TAMANHO, TAMANHO))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    return image, label"
   ],
   "id": "115533aa58ce4157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Além de aplicar o pré-processamento, os dados são organizados para serem divididos em batches para facilitar o processamento na rede e o prefetch para agilizar o processo de carregamento dos batches enquanto a rede é treinada.",
   "id": "d7d4c0b66fde6022"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:19:14.320940Z",
     "start_time": "2025-11-16T03:19:14.310745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH = 32\n",
    "ds_train = ds_train.map(preprocessamento).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val   = ds_val.map(preprocessamento).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test  = ds_test.map(preprocessamento).batch(BATCH).prefetch(tf.data.AUTOTUNE)"
   ],
   "id": "f0c527b64723db9d",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Construção do Modelo\n",
    "O modelo possui uma arquitetura sequencial, as etapas são as seguintes:\n",
    "* Recebe um input de tamanho (128, 128, 3)\n",
    "* Uma camada Convolucional com 32 filtros de formato 3x3.\n",
    "* Max Pooling de janelas 2x2.\n",
    "* Uma camada Convolucional com 64 filtros de formato 3x3.\n",
    "* Max Pooling de janelas 2x2.\n",
    "* Camadas são achatadas.\n",
    "* Camada densa inicial com 64 pontos de entrada.\n",
    "* Camada final de saída com 2 valores de ativação possíveis (cão ou gato)."
   ],
   "id": "e2a0642c7597644f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:19:14.330648Z",
     "start_time": "2025-11-16T03:19:14.326302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def construir_modelo():\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=(TAMANHO, TAMANHO, 3)),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3,), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    modelo.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return modelo"
   ],
   "id": "123cacc199a12713",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Treinamento\n",
    "O modelo arquitetado é então rodado."
   ],
   "id": "bf46b76b93aee969"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T03:24:36.408686Z",
     "start_time": "2025-11-16T03:21:43.331741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = construir_modelo()\n",
    "historico = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=5\n",
    ")\n"
   ],
   "id": "d66828cebaf32a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m542/542\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 63ms/step - accuracy: 0.6785 - loss: 0.5922 - val_accuracy: 0.7435 - val_loss: 0.5078\n",
      "Epoch 2/5\n",
      "\u001B[1m542/542\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 61ms/step - accuracy: 0.7869 - loss: 0.4546 - val_accuracy: 0.7737 - val_loss: 0.4599\n",
      "Epoch 3/5\n",
      "\u001B[1m542/542\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 62ms/step - accuracy: 0.8312 - loss: 0.3761 - val_accuracy: 0.7788 - val_loss: 0.4833\n",
      "Epoch 4/5\n",
      "\u001B[1m542/542\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 65ms/step - accuracy: 0.8706 - loss: 0.3021 - val_accuracy: 0.7880 - val_loss: 0.5015\n",
      "Epoch 5/5\n",
      "\u001B[1m542/542\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m36s\u001B[0m 66ms/step - accuracy: 0.8977 - loss: 0.2386 - val_accuracy: 0.7786 - val_loss: 0.5741\n"
     ]
    }
   ],
   "execution_count": 171
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
